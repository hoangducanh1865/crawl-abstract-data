{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  1\n",
      "✅✅ 1\n",
      "✅✅ 2\n",
      "*** https://vjol.info.vn/index.php/yhlsbvbm/issue/archive/2\n",
      "**  2\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7936\n",
      "✅✅✅ 1\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7936\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7935\n",
      "✅✅✅ 2\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7935\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7908\n",
      "✅✅✅ 3\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7908\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5462\n",
      "✅✅✅ 4\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5462\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5461\n",
      "✅✅✅ 5\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5461\n",
      "***  5\n",
      "✅✅✅✅ 1\n",
      "✅✅✅✅ 2\n",
      "✅✅✅✅ 3\n",
      "✅✅✅✅ 4\n",
      "✅✅✅✅ 5\n",
      "✅✅✅✅ 6\n",
      "✅✅✅✅ 7\n",
      "✅✅✅✅ 8\n",
      "✅✅✅✅ 9\n",
      "✅✅✅✅ 10\n",
      "✅✅✅✅ 11\n",
      "✅✅✅✅ 12\n",
      "✅✅✅✅ 13\n",
      "✅✅✅✅ 14\n",
      "✅✅✅✅ 15\n",
      "✅✅✅✅ 16\n",
      "✅✅✅✅ 17\n",
      "✅✅✅✅ 18\n",
      "✅✅✅✅ 19\n",
      "✅✅✅✅ 20\n",
      "✅✅✅✅ 21\n",
      "✅✅✅✅ 22\n",
      "✅✅✅✅ 23\n",
      "✅✅✅✅ 24\n",
      "✅✅✅✅ 25\n",
      "✅✅✅✅ 26\n",
      "✅✅✅✅ 27\n",
      "✅✅✅✅ 28\n",
      "✅✅✅✅ 29\n",
      "✅✅✅✅ 30\n",
      "✅✅✅✅ 31\n",
      "✅✅✅✅ 32\n",
      "✅✅✅✅ 33\n",
      "✅✅✅✅ 34\n",
      "✅✅✅✅ 35\n",
      "✅✅✅✅ 36\n",
      "✅✅✅✅ 37\n",
      "✅✅✅✅ 38\n",
      "✅✅✅✅ 39\n",
      "✅✅✅✅ 40\n",
      "✅✅✅✅ 41\n",
      "✅✅✅✅ 42\n",
      "✅✅✅✅ 43\n",
      "✅✅✅✅ 44\n",
      "****  44\n",
      "✅ Input 1 is written into folder \"data\" successfully!\n",
      "✅ Input 2 is written into folder \"data\" successfully!\n",
      "✅ Input 3 is written into folder \"data\" successfully!\n",
      "✅ Input 4 is written into folder \"data\" successfully!\n",
      "✅ Input 5 is written into folder \"data\" successfully!\n",
      "✅ Input 6 is written into folder \"data\" successfully!\n",
      "✅ Input 7 is written into folder \"data\" successfully!\n",
      "✅ Input 8 is written into folder \"data\" successfully!\n",
      "✅ Input 9 is written into folder \"data\" successfully!\n",
      "✅ Input 10 is written into folder \"data\" successfully!\n",
      "✅ Input 11 is written into folder \"data\" successfully!\n",
      "✅ Input 12 is written into folder \"data\" successfully!\n",
      "✅ Input 13 is written into folder \"data\" successfully!\n",
      "✅ Input 14 is written into folder \"data\" successfully!\n",
      "✅ Input 15 is written into folder \"data\" successfully!\n",
      "✅ Input 16 is written into folder \"data\" successfully!\n",
      "✅ Input 17 is written into folder \"data\" successfully!\n",
      "✅ Input 18 is written into folder \"data\" successfully!\n",
      "✅ Input 19 is written into folder \"data\" successfully!\n",
      "✅ Input 20 is written into folder \"data\" successfully!\n",
      "✅ Input 21 is written into folder \"data\" successfully!\n",
      "✅ Input 22 is written into folder \"data\" successfully!\n",
      "✅ Input 23 is written into folder \"data\" successfully!\n",
      "✅ Input 24 is written into folder \"data\" successfully!\n",
      "✅ Input 25 is written into folder \"data\" successfully!\n",
      "✅ Input 26 is written into folder \"data\" successfully!\n",
      "✅ Input 27 is written into folder \"data\" successfully!\n",
      "✅ Input 28 is written into folder \"data\" successfully!\n",
      "✅ Input 29 is written into folder \"data\" successfully!\n",
      "✅ Input 30 is written into folder \"data\" successfully!\n",
      "✅ Input 31 is written into folder \"data\" successfully!\n",
      "✅ Input 32 is written into folder \"data\" successfully!\n",
      "✅ Input 33 is written into folder \"data\" successfully!\n",
      "✅ Input 34 is written into folder \"data\" successfully!\n",
      "✅ Input 35 is written into folder \"data\" successfully!\n",
      "✅ Input 36 is written into folder \"data\" successfully!\n",
      "✅ Input 37 is written into folder \"data\" successfully!\n",
      "✅ Input 38 is written into folder \"data\" successfully!\n",
      "✅ Input 39 is written into folder \"data\" successfully!\n",
      "✅ Input 40 is written into folder \"data\" successfully!\n",
      "✅ Input 41 is written into folder \"data\" successfully!\n",
      "✅ Input 42 is written into folder \"data\" successfully!\n",
      "✅ Input 43 is written into folder \"data\" successfully!\n",
      "✅ Input 44 is written into folder \"data\" successfully!\n",
      "✅ Finish batch!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning\n",
    "import warnings\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
    "\n",
    "# Thiết lập session với logic retry\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=5,  # Số lần retry tối đa\n",
    "    backoff_factor=1,  # Thời gian chờ giữa các lần retry\n",
    "    status_forcelist=[500, 502, 503, 504]  # Các mã trạng thái HTTP để retry\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "tieng_viet = [\n",
    "    'á', 'à', 'ả', 'ã', 'ạ',\n",
    "    'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ',\n",
    "    'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ',\n",
    "    'đ',\n",
    "    'é', 'è', 'ẻ', 'ẽ', 'ẹ',\n",
    "    'ê', 'ế', 'ề', 'ể', 'ễ', 'ệ',\n",
    "    'í', 'ì', 'ỉ', 'ĩ', 'ị',\n",
    "    'ó', 'ò', 'ỏ', 'õ', 'ọ',\n",
    "    'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ',\n",
    "    'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ',\n",
    "    'ú', 'ù', 'ủ', 'ũ', 'ụ',\n",
    "    'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự',\n",
    "    'Á', 'À', 'Ả', 'Ã', 'Ạ',\n",
    "    'Ă', 'Ắ', 'Ằ', 'Ẳ', 'Ẵ', 'Ặ',\n",
    "    'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ',\n",
    "    'Đ',\n",
    "    'É', 'È', 'Ẻ', 'Ẽ', 'Ẹ',\n",
    "    'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ',\n",
    "    'Í', 'Ì', 'Ỉ', 'Ĩ', 'Ị',\n",
    "    'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ',\n",
    "    'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ',\n",
    "    'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ',\n",
    "    'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ',\n",
    "    'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự'\n",
    "]\n",
    "\n",
    "keywords_to_skip = ['English', 'Tiếng Anh', '2025', '2024', '2023']\n",
    "\n",
    "def check_name(s):\n",
    "    for c in s:\n",
    "        if c in tieng_viet: \n",
    "            return False # La tieng Viet\n",
    "    return True # La tieng Anh\n",
    "\n",
    "source_url = 'https://vjol.info.vn/'\n",
    "source_response = session.get(source_url, verify=False)\n",
    "source_content = BeautifulSoup(source_response.text, 'lxml')\n",
    "all_source_urls = source_content.find_all('a')\n",
    "base_pre_pre_urls = []\n",
    "cnt = 0\n",
    "# for url in all_source_urls:\n",
    "    \n",
    "#     href = url.get('href')\n",
    "#     if url.find('img'):\n",
    "#         cnt += 1\n",
    "#         print('✅', cnt)\n",
    "#         if cnt >= 3: # Start\n",
    "#             base_pre_pre_urls.append(href + '/issue/archive')\n",
    "#         if cnt >= 3: # End\n",
    "#             break\n",
    "# base_pre_pre_urls.pop(0)\n",
    "# base_pre_pre_urls.pop()\n",
    "\n",
    "base_pre_pre_urls.append('https://vjol.info.vn/index.php/yhlsbvbm/issue/archive')\n",
    "\n",
    "print('* ', len(base_pre_pre_urls))\n",
    "\n",
    "pre_pre_pdf_urls = [] \n",
    "cnt = 0\n",
    "for base_pre_pre_url in base_pre_pre_urls:\n",
    "    cnt += 1\n",
    "    print('✅✅', cnt)\n",
    "    pre_pre_pdf_urls.append(base_pre_pre_url) # Them trang dau tien vao list\n",
    "\n",
    "    count = 2\n",
    "    pre_pre_pdf_url = base_pre_pre_url + '/' + str(count)\n",
    "    response = session.get(pre_pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    while 'Kế tiếp' in content.text:\n",
    "        cnt += 1\n",
    "        print('✅✅', cnt)\n",
    "        pre_pre_pdf_urls.append(pre_pre_pdf_url)\n",
    "        print('***', pre_pre_pdf_url)\n",
    "        count += 1\n",
    "        pre_pre_pdf_url = base_pre_pre_url + '/' + str(count)\n",
    "        response = session.get(pre_pre_pdf_url, verify=False)\n",
    "        content = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "    cnt += 1\n",
    "    print('✅✅', cnt)\n",
    "    pre_pre_pdf_urls.append(pre_pre_pdf_url)  # Them trang cuoi cung vao list\n",
    "    print('***', pre_pre_pdf_url)\n",
    "\n",
    "# print(pre_pre_pdf_urls)\n",
    "print('** ', len(pre_pre_pdf_urls))\n",
    "\n",
    "pre_pdf_urls = []\n",
    "cnt = 0\n",
    "for pre_pre_pdf_url in pre_pre_pdf_urls:\n",
    "    response = session.get(pre_pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "    all_urls = content.find_all('a')\n",
    "\n",
    "    for url in all_urls:\n",
    "        try:\n",
    "            href = url['href']\n",
    "            if pre_pre_pdf_url[-1] == 'e':\n",
    "                keychain = pre_pre_pdf_url.replace('archive', 'view/')\n",
    "            else:\n",
    "                keychain = pre_pre_pdf_url.replace(r'archive/\\d+$', 'view/')\n",
    "            \n",
    "            if keychain in href: # Co truong hop href bi lap, co truong hop thi khong\n",
    "                print(href)\n",
    "                if any(keyword in url.text for keyword in keywords_to_skip):\n",
    "                    print('💛', url.text)\n",
    "                    if len(pre_pdf_urls) != 0 and href == pre_pdf_urls[-1]:\n",
    "                        pre_pdf_urls.pop()\n",
    "                    continue\n",
    "                if len(pre_pdf_urls) != 0 and href == pre_pdf_urls[-1]: \n",
    "                    continue \n",
    "                cnt += 1\n",
    "                print('✅✅✅', cnt)\n",
    "                pre_pdf_urls.append(href)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "             \n",
    "# print(pre_pdf_urls)\n",
    "print('*** ', len(pre_pdf_urls))\n",
    "\n",
    "pdf_urls = []\n",
    "cnt = 0\n",
    "for pre_pdf_url in pre_pdf_urls:\n",
    "    response = session.get(pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "    all_urls = content.find_all('a')\n",
    "\n",
    "    for url in all_urls:\n",
    "        href = url['href']\n",
    "        try:\n",
    "            keychain = pre_pdf_url.replace('issue', 'article')\n",
    "            keychain = re.sub(r'/\\d+$', '', keychain)\n",
    "            # print('***', keychain) \n",
    "            \n",
    "            if re.match(re.escape(keychain) + r'/\\d+/\\d+$', href):\n",
    "                pdf_url = href.replace('view', 'download') \n",
    "                if 'English' in url.text or 'Tiếng Anh' in url.text:\n",
    "                    if len(pdf_urls) != 0 and href == pdf_urls[-1]:\n",
    "                        pdf_urls.pop()\n",
    "                    continue\n",
    "                if len(pdf_urls) != 0 and pdf_url == pdf_urls[-1]:\n",
    "                    continue\n",
    "                cnt += 1\n",
    "                print('✅✅✅✅', cnt)\n",
    "                pdf_urls.append(pdf_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            \n",
    "# print(pdf_urls)\n",
    "print('**** ', len(pdf_urls))\n",
    "            \n",
    "count = 0\n",
    "for pdf_url in pdf_urls:\n",
    "    \n",
    "    try:\n",
    "        pdf_response = session.get(pdf_url, verify=False)\n",
    "        count += 1\n",
    "        file_name = \"input\" + str(count) + '.pdf'\n",
    "        \n",
    "        with open('/Users/hoangducanh/Documents/Hoc o HUST/nhom_anh_minh/crawl-abstract-data/data/input/yhlsbvbm/' + file_name, 'wb') as f:\n",
    "            f.write(pdf_response.content)\n",
    "            print('✅ Input {} is written into folder \"data\" successfully!'.format(count))\n",
    "    except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "print('✅ Finish batch!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
