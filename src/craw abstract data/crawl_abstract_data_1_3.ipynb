{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  1\n",
      "âœ…âœ… 1\n",
      "âœ…âœ… 2\n",
      "*** https://vjol.info.vn/index.php/yhlsbvbm/issue/archive/2\n",
      "**  2\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7936\n",
      "âœ…âœ…âœ… 1\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7936\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7935\n",
      "âœ…âœ…âœ… 2\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7935\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7908\n",
      "âœ…âœ…âœ… 3\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/7908\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5462\n",
      "âœ…âœ…âœ… 4\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5462\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5461\n",
      "âœ…âœ…âœ… 5\n",
      "https://vjol.info.vn/index.php/yhlsbvbm/issue/view/5461\n",
      "***  5\n",
      "âœ…âœ…âœ…âœ… 1\n",
      "âœ…âœ…âœ…âœ… 2\n",
      "âœ…âœ…âœ…âœ… 3\n",
      "âœ…âœ…âœ…âœ… 4\n",
      "âœ…âœ…âœ…âœ… 5\n",
      "âœ…âœ…âœ…âœ… 6\n",
      "âœ…âœ…âœ…âœ… 7\n",
      "âœ…âœ…âœ…âœ… 8\n",
      "âœ…âœ…âœ…âœ… 9\n",
      "âœ…âœ…âœ…âœ… 10\n",
      "âœ…âœ…âœ…âœ… 11\n",
      "âœ…âœ…âœ…âœ… 12\n",
      "âœ…âœ…âœ…âœ… 13\n",
      "âœ…âœ…âœ…âœ… 14\n",
      "âœ…âœ…âœ…âœ… 15\n",
      "âœ…âœ…âœ…âœ… 16\n",
      "âœ…âœ…âœ…âœ… 17\n",
      "âœ…âœ…âœ…âœ… 18\n",
      "âœ…âœ…âœ…âœ… 19\n",
      "âœ…âœ…âœ…âœ… 20\n",
      "âœ…âœ…âœ…âœ… 21\n",
      "âœ…âœ…âœ…âœ… 22\n",
      "âœ…âœ…âœ…âœ… 23\n",
      "âœ…âœ…âœ…âœ… 24\n",
      "âœ…âœ…âœ…âœ… 25\n",
      "âœ…âœ…âœ…âœ… 26\n",
      "âœ…âœ…âœ…âœ… 27\n",
      "âœ…âœ…âœ…âœ… 28\n",
      "âœ…âœ…âœ…âœ… 29\n",
      "âœ…âœ…âœ…âœ… 30\n",
      "âœ…âœ…âœ…âœ… 31\n",
      "âœ…âœ…âœ…âœ… 32\n",
      "âœ…âœ…âœ…âœ… 33\n",
      "âœ…âœ…âœ…âœ… 34\n",
      "âœ…âœ…âœ…âœ… 35\n",
      "âœ…âœ…âœ…âœ… 36\n",
      "âœ…âœ…âœ…âœ… 37\n",
      "âœ…âœ…âœ…âœ… 38\n",
      "âœ…âœ…âœ…âœ… 39\n",
      "âœ…âœ…âœ…âœ… 40\n",
      "âœ…âœ…âœ…âœ… 41\n",
      "âœ…âœ…âœ…âœ… 42\n",
      "âœ…âœ…âœ…âœ… 43\n",
      "âœ…âœ…âœ…âœ… 44\n",
      "****  44\n",
      "âœ… Input 1 is written into folder \"data\" successfully!\n",
      "âœ… Input 2 is written into folder \"data\" successfully!\n",
      "âœ… Input 3 is written into folder \"data\" successfully!\n",
      "âœ… Input 4 is written into folder \"data\" successfully!\n",
      "âœ… Input 5 is written into folder \"data\" successfully!\n",
      "âœ… Input 6 is written into folder \"data\" successfully!\n",
      "âœ… Input 7 is written into folder \"data\" successfully!\n",
      "âœ… Input 8 is written into folder \"data\" successfully!\n",
      "âœ… Input 9 is written into folder \"data\" successfully!\n",
      "âœ… Input 10 is written into folder \"data\" successfully!\n",
      "âœ… Input 11 is written into folder \"data\" successfully!\n",
      "âœ… Input 12 is written into folder \"data\" successfully!\n",
      "âœ… Input 13 is written into folder \"data\" successfully!\n",
      "âœ… Input 14 is written into folder \"data\" successfully!\n",
      "âœ… Input 15 is written into folder \"data\" successfully!\n",
      "âœ… Input 16 is written into folder \"data\" successfully!\n",
      "âœ… Input 17 is written into folder \"data\" successfully!\n",
      "âœ… Input 18 is written into folder \"data\" successfully!\n",
      "âœ… Input 19 is written into folder \"data\" successfully!\n",
      "âœ… Input 20 is written into folder \"data\" successfully!\n",
      "âœ… Input 21 is written into folder \"data\" successfully!\n",
      "âœ… Input 22 is written into folder \"data\" successfully!\n",
      "âœ… Input 23 is written into folder \"data\" successfully!\n",
      "âœ… Input 24 is written into folder \"data\" successfully!\n",
      "âœ… Input 25 is written into folder \"data\" successfully!\n",
      "âœ… Input 26 is written into folder \"data\" successfully!\n",
      "âœ… Input 27 is written into folder \"data\" successfully!\n",
      "âœ… Input 28 is written into folder \"data\" successfully!\n",
      "âœ… Input 29 is written into folder \"data\" successfully!\n",
      "âœ… Input 30 is written into folder \"data\" successfully!\n",
      "âœ… Input 31 is written into folder \"data\" successfully!\n",
      "âœ… Input 32 is written into folder \"data\" successfully!\n",
      "âœ… Input 33 is written into folder \"data\" successfully!\n",
      "âœ… Input 34 is written into folder \"data\" successfully!\n",
      "âœ… Input 35 is written into folder \"data\" successfully!\n",
      "âœ… Input 36 is written into folder \"data\" successfully!\n",
      "âœ… Input 37 is written into folder \"data\" successfully!\n",
      "âœ… Input 38 is written into folder \"data\" successfully!\n",
      "âœ… Input 39 is written into folder \"data\" successfully!\n",
      "âœ… Input 40 is written into folder \"data\" successfully!\n",
      "âœ… Input 41 is written into folder \"data\" successfully!\n",
      "âœ… Input 42 is written into folder \"data\" successfully!\n",
      "âœ… Input 43 is written into folder \"data\" successfully!\n",
      "âœ… Input 44 is written into folder \"data\" successfully!\n",
      "âœ… Finish batch!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning\n",
    "import warnings\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
    "\n",
    "# Thiáº¿t láº­p session vá»›i logic retry\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=5,  # Sá»‘ láº§n retry tá»‘i Ä‘a\n",
    "    backoff_factor=1,  # Thá»i gian chá» giá»¯a cÃ¡c láº§n retry\n",
    "    status_forcelist=[500, 502, 503, 504]  # CÃ¡c mÃ£ tráº¡ng thÃ¡i HTTP Ä‘á»ƒ retry\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "tieng_viet = [\n",
    "    'Ã¡', 'Ã ', 'áº£', 'Ã£', 'áº¡',\n",
    "    'Äƒ', 'áº¯', 'áº±', 'áº³', 'áºµ', 'áº·',\n",
    "    'Ã¢', 'áº¥', 'áº§', 'áº©', 'áº«', 'áº­',\n",
    "    'Ä‘',\n",
    "    'Ã©', 'Ã¨', 'áº»', 'áº½', 'áº¹',\n",
    "    'Ãª', 'áº¿', 'á»', 'á»ƒ', 'á»…', 'á»‡',\n",
    "    'Ã­', 'Ã¬', 'á»‰', 'Ä©', 'á»‹',\n",
    "    'Ã³', 'Ã²', 'á»', 'Ãµ', 'á»',\n",
    "    'Ã´', 'á»‘', 'á»“', 'á»•', 'á»—', 'á»™',\n",
    "    'Æ¡', 'á»›', 'á»', 'á»Ÿ', 'á»¡', 'á»£',\n",
    "    'Ãº', 'Ã¹', 'á»§', 'Å©', 'á»¥',\n",
    "    'Æ°', 'á»©', 'á»«', 'á»­', 'á»¯', 'á»±',\n",
    "    'Ã', 'Ã€', 'áº¢', 'Ãƒ', 'áº ',\n",
    "    'Ä‚', 'áº®', 'áº°', 'áº²', 'áº´', 'áº¶',\n",
    "    'Ã‚', 'áº¤', 'áº¦', 'áº¨', 'áºª', 'áº¬',\n",
    "    'Ä',\n",
    "    'Ã‰', 'Ãˆ', 'áºº', 'áº¼', 'áº¸',\n",
    "    'ÃŠ', 'áº¾', 'á»€', 'á»‚', 'á»„', 'á»†',\n",
    "    'Ã', 'ÃŒ', 'á»ˆ', 'Ä¨', 'á»Š',\n",
    "    'Ã“', 'Ã’', 'á»Ž', 'Ã•', 'á»Œ',\n",
    "    'Ã”', 'á»', 'á»’', 'á»”', 'á»–', 'á»˜',\n",
    "    'Æ ', 'á»š', 'á»œ', 'á»ž', 'á» ', 'á»¢',\n",
    "    'Ãš', 'Ã™', 'á»¦', 'Å¨', 'á»¤',\n",
    "    'Æ¯', 'á»¨', 'á»ª', 'á»¬', 'á»®', 'á»°'\n",
    "]\n",
    "\n",
    "keywords_to_skip = ['English', 'Tiáº¿ng Anh', '2025', '2024', '2023']\n",
    "\n",
    "def check_name(s):\n",
    "    for c in s:\n",
    "        if c in tieng_viet: \n",
    "            return False # La tieng Viet\n",
    "    return True # La tieng Anh\n",
    "\n",
    "source_url = 'https://vjol.info.vn/'\n",
    "source_response = session.get(source_url, verify=False)\n",
    "source_content = BeautifulSoup(source_response.text, 'lxml')\n",
    "all_source_urls = source_content.find_all('a')\n",
    "base_pre_pre_urls = []\n",
    "cnt = 0\n",
    "# for url in all_source_urls:\n",
    "    \n",
    "#     href = url.get('href')\n",
    "#     if url.find('img'):\n",
    "#         cnt += 1\n",
    "#         print('âœ…', cnt)\n",
    "#         if cnt >= 3: # Start\n",
    "#             base_pre_pre_urls.append(href + '/issue/archive')\n",
    "#         if cnt >= 3: # End\n",
    "#             break\n",
    "# base_pre_pre_urls.pop(0)\n",
    "# base_pre_pre_urls.pop()\n",
    "\n",
    "base_pre_pre_urls.append('https://vjol.info.vn/index.php/yhlsbvbm/issue/archive')\n",
    "\n",
    "print('* ', len(base_pre_pre_urls))\n",
    "\n",
    "pre_pre_pdf_urls = [] \n",
    "cnt = 0\n",
    "for base_pre_pre_url in base_pre_pre_urls:\n",
    "    cnt += 1\n",
    "    print('âœ…âœ…', cnt)\n",
    "    pre_pre_pdf_urls.append(base_pre_pre_url) # Them trang dau tien vao list\n",
    "\n",
    "    count = 2\n",
    "    pre_pre_pdf_url = base_pre_pre_url + '/' + str(count)\n",
    "    response = session.get(pre_pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    while 'Káº¿ tiáº¿p' in content.text:\n",
    "        cnt += 1\n",
    "        print('âœ…âœ…', cnt)\n",
    "        pre_pre_pdf_urls.append(pre_pre_pdf_url)\n",
    "        print('***', pre_pre_pdf_url)\n",
    "        count += 1\n",
    "        pre_pre_pdf_url = base_pre_pre_url + '/' + str(count)\n",
    "        response = session.get(pre_pre_pdf_url, verify=False)\n",
    "        content = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "    cnt += 1\n",
    "    print('âœ…âœ…', cnt)\n",
    "    pre_pre_pdf_urls.append(pre_pre_pdf_url)  # Them trang cuoi cung vao list\n",
    "    print('***', pre_pre_pdf_url)\n",
    "\n",
    "# print(pre_pre_pdf_urls)\n",
    "print('** ', len(pre_pre_pdf_urls))\n",
    "\n",
    "pre_pdf_urls = []\n",
    "cnt = 0\n",
    "for pre_pre_pdf_url in pre_pre_pdf_urls:\n",
    "    response = session.get(pre_pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "    all_urls = content.find_all('a')\n",
    "\n",
    "    for url in all_urls:\n",
    "        try:\n",
    "            href = url['href']\n",
    "            if pre_pre_pdf_url[-1] == 'e':\n",
    "                keychain = pre_pre_pdf_url.replace('archive', 'view/')\n",
    "            else:\n",
    "                keychain = pre_pre_pdf_url.replace(r'archive/\\d+$', 'view/')\n",
    "            \n",
    "            if keychain in href: # Co truong hop href bi lap, co truong hop thi khong\n",
    "                print(href)\n",
    "                if any(keyword in url.text for keyword in keywords_to_skip):\n",
    "                    print('ðŸ’›', url.text)\n",
    "                    if len(pre_pdf_urls) != 0 and href == pre_pdf_urls[-1]:\n",
    "                        pre_pdf_urls.pop()\n",
    "                    continue\n",
    "                if len(pre_pdf_urls) != 0 and href == pre_pdf_urls[-1]: \n",
    "                    continue \n",
    "                cnt += 1\n",
    "                print('âœ…âœ…âœ…', cnt)\n",
    "                pre_pdf_urls.append(href)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "             \n",
    "# print(pre_pdf_urls)\n",
    "print('*** ', len(pre_pdf_urls))\n",
    "\n",
    "pdf_urls = []\n",
    "cnt = 0\n",
    "for pre_pdf_url in pre_pdf_urls:\n",
    "    response = session.get(pre_pdf_url, verify=False)\n",
    "    content = BeautifulSoup(response.text, 'lxml')\n",
    "    all_urls = content.find_all('a')\n",
    "\n",
    "    for url in all_urls:\n",
    "        href = url['href']\n",
    "        try:\n",
    "            keychain = pre_pdf_url.replace('issue', 'article')\n",
    "            keychain = re.sub(r'/\\d+$', '', keychain)\n",
    "            # print('***', keychain) \n",
    "            \n",
    "            if re.match(re.escape(keychain) + r'/\\d+/\\d+$', href):\n",
    "                pdf_url = href.replace('view', 'download') \n",
    "                if 'English' in url.text or 'Tiáº¿ng Anh' in url.text:\n",
    "                    if len(pdf_urls) != 0 and href == pdf_urls[-1]:\n",
    "                        pdf_urls.pop()\n",
    "                    continue\n",
    "                if len(pdf_urls) != 0 and pdf_url == pdf_urls[-1]:\n",
    "                    continue\n",
    "                cnt += 1\n",
    "                print('âœ…âœ…âœ…âœ…', cnt)\n",
    "                pdf_urls.append(pdf_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            \n",
    "# print(pdf_urls)\n",
    "print('**** ', len(pdf_urls))\n",
    "            \n",
    "count = 0\n",
    "for pdf_url in pdf_urls:\n",
    "    \n",
    "    try:\n",
    "        pdf_response = session.get(pdf_url, verify=False)\n",
    "        count += 1\n",
    "        file_name = \"input\" + str(count) + '.pdf'\n",
    "        \n",
    "        with open('/Users/hoangducanh/Documents/Hoc o HUST/nhom_anh_minh/crawl-abstract-data/data/input/yhlsbvbm/' + file_name, 'wb') as f:\n",
    "            f.write(pdf_response.content)\n",
    "            print('âœ… Input {} is written into folder \"data\" successfully!'.format(count))\n",
    "    except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "print('âœ… Finish batch!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
